{
 "cells": [
    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Import basic libraries and keras\n",
"import os\n",
"import json\n",
"from keras import layers\n",
"from keras.layers import LSTM\n",
"from keras.models import Model\n",
"from keras.models import load_model\n",
"from stories import get_stories, vectorize_stories\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Set parameters\n",
"EMBED_HIDDEN_SIZE = 50\n",
"SENT_HIDDEN_SIZE = 100\n",
"QUERY_HIDDEN_SIZE = 100\n",
"BATCH_SIZE = 32\n",
"EPOCHS = 40\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Load input data\n",
"train = get_stories('qa1_single-supporting-fact_train.txt')\n",
"test = get_stories('qa1_single-supporting-fact_test.txt')\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Create vocabulary\n",
"vocab = set()\n",
"for story, q, answer in train + test:\n",
"    vocab |= set(story + q + [answer])\n",
"vocab = sorted(vocab)\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Create index of words {word: id}\n",
"# Reserve 0 for masking via pad_sequences\n",
"vocab_size = len(vocab) + 1\n",
"word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
"# Get maximum length of sequences\n",
"story_maxlen = max(map(len, (x for x, _, _ in train + test)))\n",
"query_maxlen = max(map(len, (x for _, x, _ in train + test)))\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Save vocabulary and lengths to file\n",
"if not os.path.exists('dictionary.json'):\n",
"    with open('dictionary.json', 'w') as outfile:\n",
"        json.dump(word_idx, outfile)\n",
"if not os.path.exists('lengths.json'):\n",
"    with open('lengths.json', 'w') as outfile:\n",
"        json.dump({'story_maxlen': story_maxlen, 'query_maxlen': query_maxlen}, outfile)\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Vectorize the stories\n",
"x, xq, y = vectorize_stories(train, word_idx, story_maxlen, query_maxlen)\n",
"tx, txq, ty = vectorize_stories(test, word_idx, story_maxlen, query_maxlen)\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Check if there is a pre-trained model\n",
"if not os.path.exists('rnn_model.h5'):\n",
"    # Create a neural network for the stories\n",
"    sentence = layers.Input(shape=(story_maxlen,), dtype='int32')\n",
"    encoded_sentence = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(sentence)\n",
"    encoded_sentence = layers.Dropout(0.3)(encoded_sentence)\n",
"\n",
"    # Create a neural network for the questions\n",
"    question = layers.Input(shape=(query_maxlen,), dtype='int32')\n",
"    encoded_question = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(question)\n",
"    encoded_question = layers.Dropout(0.3)(encoded_question)\n",
"    encoded_question = LSTM(EMBED_HIDDEN_SIZE)(encoded_question)\n",
"    encoded_question = layers.RepeatVector(story_maxlen)(encoded_question)\n",
"\n",
"    # Combine the two networks\n",
"    merged = layers.add([encoded_sentence, encoded_question])\n",
"    merged = LSTM(EMBED_HIDDEN_SIZE)(merged)\n",
"    merged = layers.Dropout(0.3)(merged)\n",
"    preds = layers.Dense(vocab_size, activation='softmax')(merged)\n",
"    model = Model([sentence, question], preds)\n",
"    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
"\n",
"    # Train the model\n",
"    model.fit([x, xq], y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.05)\n",
"\n",
"    # Save the model\n",
"    model.save('rnn_model.h5')\n",
"else:\n",
"    # Load the model from disk\n",
"    model = load_model('rnn_model.h5')\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "model.summary()\n",
"score = model.evaluate([tx, txq], ty, batch_size=BATCH_SIZE, verbose=0)\n",
"print('Test loss:', score[0])\n",
"print('Test accuracy:', score[1])\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "\n"
    ]
    }],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
