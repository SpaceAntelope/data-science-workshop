{
 "cells": [
    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Import basic libraries and keras\n",
"import json\n",
"import numpy as np\n",
"from keras.models import load_model\n",
"from stories import get_stories, tokenize\n",
"from keras.preprocessing.sequence import pad_sequences\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Load test data\n",
"test_stories = get_stories('qa1_single-supporting-fact_test.txt')\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Load model, word index and lengths\n",
"model = load_model('rnn_model.h5')\n",
"with open('dictionary.json', 'r') as dictionary_file:\n",
"    word_idx = json.load(dictionary_file)\n",
"with open('lengths.json', 'r') as lengths_file:\n",
"    lengths = json.load(lengths_file)\n",
"    story_maxlen, query_maxlen = lengths[\"story_maxlen\"], lengths[\"query_maxlen\"]\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Get the word index of a question in a safe way\n",
"def best_effort_word_idxs(words):\n",
"    idxs = []\n",
"    for word in words:\n",
"        forms = [word, word.lower(), word[0].upper() + word[1:].lower()]\n",
"        for form in forms:\n",
"            if form in word_idx:\n",
"                idxs.append(word_idx[form])\n",
"    return idxs\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "while True:\n",
"    # Get a random story\n",
"    n = np.random.randint(0, 1000)\n",
"    story = test_stories[n][0]\n",
"    storystr = ' '.join(word for word in story)\n",
"    storymlstr = '\n'.join(storystr.split(' . '))[:-2]\n",
"    print(60 * '-')\n",
"    print('Story:\n' + storymlstr + '\n')\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "    # Request for a question\n",
"    print('Allowed vocabulary for questions:\n' + ' , '.join(word_idx.keys()))\n",
"    question = input('Enter your question (or press Enter to exit): ')\n",
"    if question == '':\n",
"        break\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "    # Tokenize story and question\n",
"    x = [word_idx[w] for w in story]\n",
"    xq = best_effort_word_idxs(tokenize(question)) #[word_idx[w] for w in tokenize(question)]\n",
"    if len(xq) < 1:\n",
"        print(\"Question is not valid\")\n",
"        print(60 * '-')\n",
"        input(\"Press Enter to continue...\n\")\n",
"        continue\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "    # Vectorize story and question\n",
"    tx, txq = pad_sequences([x], maxlen=story_maxlen), pad_sequences([xq], maxlen=query_maxlen)\n"
    ]
    },

    {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
        "    # Predict and print the result\n",
"    pred_results = model.predict(([tx, txq]))\n",
"    val_max = np.argmax(pred_results[0])\n",
"    for key, val in word_idx.items():\n",
"        if val == val_max:\n",
"            k = key\n",
"    print(\"Answer is: %s (confidence %.2f%%)\" %(k, 100 * pred_results[0][val_max]))\n",
"    print(60 * '-')\n",
"    input(\"Press Enter to continue...\n\")\n",
"\n"
    ]
    }],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
